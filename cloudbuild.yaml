steps:
  # DB Migration Stage
  # Step 1: Install the Cloud SQL Auth Proxy
  - id: install-proxy
    name: gcr.io/cloud-builders/wget
    entrypoint: sh
    args:
      - -c
      - |
        wget -O /workspace/cloud-sql-proxy https://storage.googleapis.com/cloud-sql-connectors/cloud-sql-proxy/v2.15.2/cloud-sql-proxy.linux.amd64
        chmod +x /workspace/cloud-sql-proxy

  # Step 2: Install dependencies including Alembic
  - name: python:3.10-slim
    id: run-db-migration
    entrypoint: bash
    secretEnv: ['CLOUDSQL_DB_USER', 'CLOUDSQL_DB_PASS']
    args:
      - "-c"
      - |
        python -m venv venv
        source venv/bin/activate
        pip install --upgrade pip
        pip install -r source/requirements.txt
          
        # start CloudSQL Proxy
        /workspace/cloud-sql-proxy ${PROJECT_ID}:${_REGION}:bookshelf-cloud-sql-instance --port ${_CLOUDSQL_PORT} & sleep 10;
        
        export DB_URL=postgresql://$$CLOUDSQL_DB_USER:$$CLOUDSQL_DB_PASS@${_CLOUDSQL_HOST}:${_CLOUDSQL_PORT}/${_CLOUDSQL_DB_NAME}
        alembic upgrade head && (echo "INFO: Migration succeed." && exit 0) || (echo "ERROR: Migration failed, check logs." && exit 1)
        deactivate

  # Docker Build and Deployment Stage
  # Step 1: Build Docker image
  - id: build-docker-image
    name: 'gcr.io/cloud-builders/docker'
    args:
      - 'build'
      - '-t'
      - '${_IMAGE_NAME}:${_IMAGE_TAG}'
      - '.'

  # Step 2: Push Docker image to Artifact Registry
  - id: push-docker-image
    name: 'gcr.io/cloud-builders/docker'
    args:
      - 'push'
      - '${_IMAGE_NAME}:${_IMAGE_TAG}'

  # Conditional deploy the new revision to Cloud Run
  - id: deploy-cloudrun
    name: 'gcr.io/cloud-builders/gcloud'
    entrypoint: "bash"
    args:
      - "-c"
      - |
        if [ "$_DEPLOY_TARGET" == "cloudrun" ]; then
          echo "Deploying to Cloud Run..."
          gcloud run deploy bookshelf-app \
            --image=${_IMAGE_NAME}:${_IMAGE_TAG} \
            --region=${_REGION} \
            --platform=managed \
            --allow-unauthenticated \
            --update-env-vars=GOOGLE_CLOUD_PROJECT=$PROJECT_ID \
            --service-account=bookshelf-sa@$PROJECT_ID.iam.gserviceaccount.com \
          && echo "Deployment finished successfully";
        fi

  # Conditional deploy the new revision to Kubernetes
  - id: deploy-kubernetes
    name: "google/cloud-sdk:latest" # Includes both gcloud and kubectl
    entrypoint: "bash"
    args:
      - "-c"
      - |
        if [ "$_DEPLOY_TARGET" == "k8s" ]; then
          echo "Deploying to Kubernetes..."
        
          # Configure access to GKE cluster
          gcloud container clusters get-credentials ${_K8S_CLUSTER} --region ${_REGION} --project ${PROJECT_ID}
          # Check that GKE context is added and visible by kubectl
          kubectl config get-contexts
        
          # Install addition utilities
          apt-get upgrade && apt-get install -y gettext-base
          envsubst --version || (echo "envsubst is not available!" && exit 1)
          
          # Apply your Kubernetes manifests
          cd kubernetes || (echo "kubernetes folder not found!" && ls -l && exit 1)
          ./k8s-deploy.sh ${_K8S_NAMESPACE} || (echo "k8s-deploy script failed!" && exit 1)
        fi


substitutions:
  _REGION: europe-north2
  _CLOUDSQL_HOST: 127.0.0.1
  _CLOUDSQL_PORT: "5432"
  _CLOUDSQL_DB_NAME: app_database
  _DATABASE_USER_KEY: cloudsql-db-user
  _DATABASE_PASSWORD_KEY: cloudsql-db-pass
  _IMAGE_NAME: europe-north2-docker.pkg.dev/cloudx-gcp-developer-rrybalkin/bookshelf-registry/bookshelf-app
  _IMAGE_TAG: latest
  _DEPLOY_TARGET: "k8s" # The deployment target; available options: ['cloudrun', 'k8s']
  _K8S_CLUSTER: "bookshelf-gke"
  _K8S_NAMESPACE: "dev"

availableSecrets:
  secretManager:
    - versionName: projects/${PROJECT_ID}/secrets/${_DATABASE_USER_KEY}/versions/latest
      env: "CLOUDSQL_DB_USER"
    - versionName: projects/${PROJECT_ID}/secrets/${_DATABASE_PASSWORD_KEY}/versions/latest
      env: "CLOUDSQL_DB_PASS"

timeout: '300s' # Set timeout for the build

# Store Logs in Cloud Logging only
options:
  logging: CLOUD_LOGGING_ONLY
